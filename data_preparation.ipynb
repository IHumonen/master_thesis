{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fcd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import torch\n",
    "\n",
    "import youtokentome as yttm\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morpher:\n",
    "    def __init__(self, pymorphy_morpher):\n",
    "        self.morpher = pymorphy_morpher\n",
    "        self.cash = dict()\n",
    "        \n",
    "    def analyze(self, word):        \n",
    "        if word in self.cash:\n",
    "            return self.cash[word]\n",
    "        else:\n",
    "            full_info = self.morpher.parse(word)[0]\n",
    "            lemma = full_info.normal_form\n",
    "            pos = full_info.tag.POS\n",
    "#             return {'lemma' : lemma, 'pos' : pos}\n",
    "            return lemma, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563ee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(corpus):\n",
    "    edges = []\n",
    "    for text in corpus:\n",
    "        for token in text:\n",
    "            for neighbour in text:\n",
    "                edge = [token2idx[token], token2idx[neighbour]]\n",
    "                if edge != [] and edge[0] != edge[1]:\n",
    "                    edges.append(edge)\n",
    "                    \n",
    "    x = torch.tensor(list(idx2token.keys()))\n",
    "    edge_index = torch.tensor(edges).transpose(0, 1)\n",
    "    graph = Data(x = x, edge_index = edge_index)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de6ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph = Morpher(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f342cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/Bunin-Temnye_allei.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40d183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'r', encoding='cp1251') as f:\n",
    "    corpus_raw = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268b7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = corpus_raw.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1336cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = set()\n",
    "corpus = []\n",
    "for text in corpus_raw:\n",
    "    text = text.split()\n",
    "    clear = []\n",
    "    for token in text:\n",
    "        lemma, pos = morph.analyze(token)\n",
    "        if pos in ['NOUN', 'INFN', 'VERB', 'ADJF']:\n",
    "            unique_tokens.add(lemma)\n",
    "            clear.append(lemma)\n",
    "    if clear != []:\n",
    "        corpus.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39a515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a974d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx = dict(zip(unique_tokens, range(len(unique_tokens))))\n",
    "idx2token = dict(zip(range(len(unique_tokens)), unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87642c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(idx2token.keys())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f43864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus, test_corpus = train_test_split(corpus, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de6acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph, test_graph = make_graph(train_corpus), make_graph(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c77c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(token2idx, 'token2idx.pickle')\n",
    "torch.save(idx2token, 'idx2token.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f99392",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_graph, 'train.pickle')\n",
    "torch.save(test_graph, 'test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be638359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.Graph(train_graph['edge_index'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7d943d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gexf(G, \"test.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c19148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_networkx(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsi",
   "language": "python",
   "name": "wsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
